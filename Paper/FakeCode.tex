\documentclass{article}

\usepackage[top=2cm, bottom=2cm, left=3cm, right=3cm]{geometry}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{amsmath}

\begin{document}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}  % Use Input in the format of Algorithm
\renewcommand{\algorithmicensure}{\textbf{Output:}} % Use Output in the format of Algorithm
\begin{algorithm}[h]
	\caption{Pseudeocode of MADQL-based ICIC} 
	% title of algorithm
	\label{alg}
	\begin{algorithmic}[1]
		\State Initialize DQN with weights wih random weights $\bm{\theta}$ and an empty experience pool $M$ for links;
		\State In time slot $t$ when number of record in memory pool smaller than $M_b$, sector takes action randomly and stores the corresponding experience $\langle s, a, r \rangle$ in its experience pool.
		\Repeat
		\State Sector $k$ build its state $s_k$ in time slot $t$ base on local CSI and exchanged CSI, $\forall k \in K$;
		\State In time slot $t(t>M_b)$, sector $k$ chooses an action $a_k$ according to $\epsilon$-greedy policy; 
		\State Sector $k$ executes the chosen action $a_k$, then gets an immediate reward $r_k=R(s_k, a_k)$, $\forall k \in K$;
		\State Sector $k$ saves its new experience $\langle s_k, a_k, r_k \rangle$ into experience pool;
		\State Samples a mini-batch consisting of $M_b$ experiences from experience pool $M$;
		\State Updates weights $\bm{\theta}$;
		\Until{$t>T_{train}$}
	\end{algorithmic}
\end{algorithm}
\end{document}